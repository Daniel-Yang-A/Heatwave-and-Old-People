{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt update \n",
    "!apt install chromium-chromedriver \n",
    "!pip install selenium \n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# These 3 urls corresponds to 3 parts of CA respectively.\n",
    "# In this block, which url is to be crawled is decided manually later.\n",
    "# And the 3 csv files that are generated seperately should be merged together by hand.\n",
    "url1 = \"https://wrcc.dri.edu/wraws/ncaF.html\"\n",
    "url2 = \"https://wrcc.dri.edu/wraws/ccaF.html\"\n",
    "url3 = \"https://wrcc.dri.edu/wraws/scaF.html\"\n",
    "\n",
    "col_names = [\"name\", \"Code\", \"Longitude\", \"Latitude\"]         \n",
    "df_data = pd.DataFrame()                        # df_data is the output of this block, i.e. the csv containing \n",
    "\n",
    "'''Browser settings'''\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_argument('--ignore-certificate-errors-spki-list')\n",
    "options.add_argument('--ignore-ssl-errors')\n",
    "options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "options.add_experimental_option(\"prefs\", {\"profile.managed_default_content_settings.images\": 2}) \n",
    "options.add_argument(\"--no-sandbox\") \n",
    "options.add_argument(\"--disable-setuid-sandbox\") \n",
    "options.add_argument(\"--disable-dev-shm-usage\") \n",
    "options.add_argument(\"--disable-extensions\") \n",
    "options.add_argument('--headless')\n",
    "options.add_argument(\"--disable-gpu\") \n",
    "options.add_argument(\"start-maximized\") \n",
    "options.add_argument(\"disable-infobars\")\n",
    "options.add_argument(r\"user-data-dir=.\\cookies\\\\test\") \n",
    "options.add_experimental_option(\"detach\", True)\n",
    "\n",
    "Name = []\n",
    "Code = []\n",
    "Longitude= []\n",
    "Latitude = []\n",
    "\n",
    "\n",
    "'''Launch the browser'''\n",
    "driver = webdriver.Chrome(options=options)  \n",
    "driver.get(url3)            # Here the url should be changed manually\n",
    "\n",
    "time.sleep(0.2)\n",
    "\n",
    "driver.maximize_window()\n",
    "\n",
    "time.sleep(0.2)\n",
    "\n",
    "# Find all the tr elements in the desired table\n",
    "iframe = driver.find_elements(by='xpath', value='//frameset/frame[@name=\"list\"]')[0]\n",
    "driver.switch_to.frame(iframe)\n",
    "\n",
    "info_list = driver.find_elements(by='xpath', value='//html/body/a')   \n",
    "    \n",
    "loc_url = \"https://wrcc.dri.edu/cgi-bin/wea_info.pl?ca\"\n",
    "for item in info_list:            # Each item is a row (station) in the navigation table of the url3\n",
    "  name = item.text\n",
    "  if name.endswith(\"California\"):\n",
    "      url = item.get_attribute(\"href\")\n",
    "      code = url[-4:]\n",
    "      Code.append(code)\n",
    "      Name.append(name)!apt update \n",
    "!apt install chromium-chromedriver \n",
    "!pip install selenium \n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# These 3 urls corresponds to 3 parts of CA respectively.\n",
    "# In this block, which url is to be crawled is decided manually later.\n",
    "# And the 3 csv files that are generated seperately should be merged together by hand.\n",
    "url1 = \"https://wrcc.dri.edu/wraws/ncaF.html\"\n",
    "url2 = \"https://wrcc.dri.edu/wraws/ccaF.html\"\n",
    "url3 = \"https://wrcc.dri.edu/wraws/scaF.html\"\n",
    "\n",
    "col_names = [\"name\", \"Code\", \"Longitude\", \"Latitude\"]         \n",
    "df_data = pd.DataFrame()                        # df_data is the output of this block, i.e. the csv containing \n",
    "\n",
    "'''Browser settings'''\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_argument('--ignore-certificate-errors-spki-list')\n",
    "options.add_argument('--ignore-ssl-errors')\n",
    "options.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "options.add_experimental_option(\"prefs\", {\"profile.managed_default_content_settings.images\": 2}) \n",
    "options.add_argument(\"--no-sandbox\") \n",
    "options.add_argument(\"--disable-setuid-sandbox\") \n",
    "options.add_argument(\"--disable-dev-shm-usage\") \n",
    "options.add_argument(\"--disable-extensions\") \n",
    "options.add_argument('--headless')\n",
    "options.add_argument(\"--disable-gpu\") \n",
    "options.add_argument(\"start-maximized\") \n",
    "options.add_argument(\"disable-infobars\")\n",
    "options.add_argument(r\"user-data-dir=.\\cookies\\\\test\") \n",
    "options.add_experimental_option(\"detach\", True)\n",
    "\n",
    "Name = []\n",
    "Code = []\n",
    "Longitude= []\n",
    "Latitude = []\n",
    "\n",
    "\n",
    "'''Launch the browser'''\n",
    "driver = webdriver.Chrome(options=options)  \n",
    "driver.get(url3)            # Here the url should be changed manually\n",
    "\n",
    "time.sleep(0.2)\n",
    "\n",
    "driver.maximize_window()\n",
    "\n",
    "time.sleep(0.2)\n",
    "\n",
    "# Find all the tr elements in the desired table\n",
    "iframe = driver.find_elements(by='xpath', value='//frameset/frame[@name=\"list\"]')[0]\n",
    "driver.switch_to.frame(iframe)\n",
    "\n",
    "info_list = driver.find_elements(by='xpath', value='//html/body/a')   \n",
    "    \n",
    "loc_url = \"https://wrcc.dri.edu/cgi-bin/wea_info.pl?ca\"\n",
    "for item in info_list:            # Each item is a row (station) in the navigation table of the url3\n",
    "  name = item.text\n",
    "  if name.endswith(\"California\"):\n",
    "      url = item.get_attribute(\"href\")\n",
    "      code = url[-4:]\n",
    "      Code.append(code)\n",
    "      Name.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each station, find its geography info (longitude and latitude) \n",
    "for code in Code:\n",
    "  \n",
    "      loc_web = loc_url + code\n",
    "\n",
    "      driver.get(loc_web)\n",
    "      time.sleep(0.2)\n",
    "\n",
    "      tr_list = driver.find_elements(by='xpath', value='//body/blockquote/table/tbody/tr') \n",
    "\n",
    "      longi = tr_list[2].text\n",
    "      lati = tr_list[1].text\n",
    "      longitude = longi[10: longi.index('\"')+1]\n",
    "      latitude = lati[9:lati.index('\"')+1]\n",
    "      \n",
    "      Longitude.append(longitude)\n",
    "      Latitude.append(latitude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the info\n",
    "df_data[\"name\"] = Name\n",
    "df_data[\"code\"] = Code\n",
    "df_data[\"Longitude\"] = Longitude\n",
    "df_data[\"Latitude\"] = Latitude\n",
    "df_data.to_csv(\"NCA.csv\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "861f9c34f7302a1aedb62edfc1533c524ce2793735e6b405602ea89eb9cb2484"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
